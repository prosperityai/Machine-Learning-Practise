{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112197, 30)\n"
     ]
    }
   ],
   "source": [
    "input_sentiment = pd.read_csv(\"sentiment_data.csv\", header=0, delimiter=\",\")\n",
    "input_sentiment['s_indicator']=0\n",
    "print (input_sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provisioning for part-of-speech tagging\n",
    "def penn_to_wn(tag):\n",
    "     if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "     elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "     elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "     elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swn_polarity(text):\n",
    "    sentiment = 0\n",
    "    tokens_count = 0\n",
    "    \n",
    "    for raw_sentence in text:\n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    "        \n",
    "        for word, tag in tagged_sentence:\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "                continue\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    " \n",
    "            \n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            #Assigning sentiment score\n",
    "            sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "            tokens_count += 1\n",
    "            \n",
    "            if not tokens_count:\n",
    "                return 0\n",
    "            if sentiment >= 0:\n",
    "                return 1\n",
    "            \n",
    "\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taking users review data for analysis\n",
    "review_data = input_sentiment[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsentiment=[]\n",
    "\n",
    "for i in review_data:\n",
    "    lsentiment.append(swn_polarity(i))\n",
    "    resultsentiment=zip(review_data,lsentiment)\n",
    "    input_sentiment['s_indicator']=pd.Series(lsentiment)\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Regression (Logistic) on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = input_sentiment[:90000] \n",
    "test = input_sentiment[90000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data cleansing\n",
    "train = train.fillna(0)\n",
    "test=test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.306467\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             lsentiment   No. Observations:                90000\n",
      "Model:                          Logit   Df Residuals:                    89999\n",
      "Method:                           MLE   Df Model:                            0\n",
      "Date:                Mon, 27 Feb 2017   Pseudo R-squ.:                -0.05248\n",
      "Time:                        15:51:59   Log-Likelihood:                -27582.\n",
      "converged:                       True   LL-Null:                       -26207.\n",
      "                                        LLR p-value:                       nan\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "overall        0.5217      0.003    191.052      0.000         0.516     0.527\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logit = sm2.Logit(train['s_indicator'].dropna(),train['overall'].dropna())\n",
    "result = logit.fit() \n",
    "print (result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#prediction of sentiment based on confidence\n",
    "predictSentiment = result.predict(test['overall'])\n",
    "\n",
    "predictSentiment = (predictSentiment > 0.50).astype(int)\n",
    "print(predictSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[    0  1860]\n",
      " [    0 20337]]\n"
     ]
    }
   ],
   "source": [
    "#Generating a confusion mmatrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print (confusion_matrix(test['lsentiment'],predictSentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916204892553\n"
     ]
    }
   ],
   "source": [
    "#Deriving accuracy scores\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(test['s_indicator'],predictSentiment))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
